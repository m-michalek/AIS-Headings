---
title: "Headline"
author: "Tino Wagner, Max Michalek, Lukas Ziebold"
date: "6 Juni 2018"
---

PREPERATION

```{r}
#install/load packages: tidyvers, tidytext
#install.packages("magrittr")
#install.packages("tidyverse")
#install.packages("tidytext")
#install.packages("wordcloud")
library(tidyverse)
library(tidytext)
library(magrittr)
library(plyr)
library(dplyr)
library(ggplot2)
library(wordcloud)

#Importieren der Datensätze
batches <- read.csv("./Honeypot_subset/HWR_DATA_batches_subset.csv")
salaries <- read.csv("./Honeypot_subset/HWR_DATA_salaries_subset.csv")
talents <- read.csv("./Honeypot_subset/HWR_DATA_talents_subset.csv")

```

Text Mining
```{r}
# Filtern nach allen Talenten mit einer Headline
with_headlines <- talents %>% 
  filter(talents$headline != "")

# Filtern nach allen Talenten ohne einer Headline
without_headlines <- talents %>% 
  filter(talents$headline == "")

# Erstellen eines Data Frames mit "talent_id" und "headline"
headlines_df <- data_frame(talent_id = with_headlines$talent_id, headline = as.vector(with_headlines$headline))

# Aufteilen von eine Headline pro Reihe in ein Wort pro Reihe ohne die Zuordnung zum Talent zu verlieren
unnested_headlines <- headlines_df %>%
  unnest_tokens(word, headline)

# Auflistung der Häufigkeiten wie oft ein Wort pro Headline vorkommt
# Stopwords werden entfernt und nach der Häufigkeit sortiert
word_count <- unnested_headlines %>%
  anti_join(stop_words) %>%
  group_by(talent_id ,word) %>% 
  count_() %>% 
  arrange(-n)
  
# Auflistung der Gesamthäufigkeit der Wörter in den Headlines
word_count_per_talent_id <- word_count %>% 
  group_by(word) %>% 
  count_() %>% 
  arrange(-nn)

colnames(word_count_per_talent_id) <- c("word", "n")

# Anzahl der insgesamt genutzen Wörter pro Talent
word_count_per_headline <- unnested_headlines %>%
  anti_join(stop_words) %>%
  group_by(talent_id) %>% 
  count_() %>% 
  arrange(-n)

# Anpassung der Levels des Factor word für eine passende Reihenfolge beim plotten
word_count_per_talent_id$word <- factor(word_count_per_talent_id$word, levels = word_count_per_talent_id$word)

# Erstellen eines neuen Data Frames für die populärsten 20 Wörter und ihrer Häufigkeit
most_20_words <- data_frame(word = word_count_per_talent_id$word[1:20], n = word_count_per_talent_id$n[1:20])

# Dem neuen Data Frame werden alle weiteren Wörter und ihrer Häufigkeit unter dem Wort "Other words" hinzugefügt
most_20_words <- rbind(most_20_words, data.frame(word = "Other words", n = sum(word_count_per_talent_id$n[21:length(word_count_per_talent_id)])))

# Anpassung der Levels des Factor word für eine passende Reihenfolge beim plotten
most_20_words$word <- factor(most_20_words$word, levels = most_20_words$word)

A_most_20_words <-most_20_words  %>% top_n(20)

# Erstellung eines Colcharts zur visualisierung der populärsten 20 Wörter
# Aus ästhetischen Gründen wurde "Other words" rausgerechnet
most_20_words %>%
  filter (word!="Other words") %>%
  ggplot(aes(x = word, y = n, fill=n)) +
  geom_col()+
  theme(text = element_text(size=20),
        axis.text.x = element_text(angle=90, hjust=1), legend.position = "none")+
  ylab("Count")+
  xlab("Word")

# Auflistung aller Talente welche zu einem Interview eingeladen wurden (12060)
invited_to_call <- talents %>% 
  filter(invited_to_call == 1)

# Auflistung alle Talente die Gebatched wurden, jedoch nicht zu einem Interview eingeladen wurden
talents %>%
  filter(was_batched == 1, interview_invites != 0) %>% 
  count_()

# Auflistung aller Talente die von einem Arbeitgeber eingestellt wurden
talents %>% 
  filter(was_hired == 1) %>% 
  count_()

# Wort auftreten in batched und !Wort in batched
#bb
was_batched <- talents %>% 
  filter(was_batched == 1) %>% 
  left_join(word_count)

was_batched <- was_batched[c("talent_id", "word", "n")]

was_batched <- was_batched %>% 
  count_("word") %>% 
  arrange(-nn) %>% 
  mutate("propability" = nn / was_batched %>% 
           group_by(talent_id) %>% 
           count_() %>% 
           nrow()
         )

colnames(was_batched) <- c("word", "n_was_bached", "propability_was_bached")

#word count impact
invited_word_count <-unnested_headlines %>% 
    anti_join(stop_words) %>%
  # Group by each word
   inner_join(talents) %>% 
  group_by(word) %>% 
  filter(interview_invites > 0)%>%
   count_() %>% 
  arrange(-n)

invited_word_count [1:20,] %>%
  arrange(-n)%>%
  ggplot(aes(x = reorder(word, -n) , y = n,fill = n)) +
  geom_col()+
  theme(text = element_text(size=20), axis.text.x = element_text(angle=90, hjust=1),legend.position="none")+
  ylab("Talents invited to Interview")+
  xlab("Word")

hired_word_count <-unnested_headlines %>% 
  anti_join(stop_words) %>%
  # Group by each word
  inner_join(talents) %>% 
  group_by(word) %>% 
  filter(was_hired==1)%>%
  count_() %>% 
  arrange(-n)

#id die gebached wurden in develop benutzen
#Anzahl der Leute die gebatched wurden und developer in der headline haben
word_count %>% 
  filter(word == "developer") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0) %>% 
  nrow() %>% 
  View()

#Anzahl der Leute die gebatched wurden und !developer in der headline haben
developer_in_headline <- word_count %>% 
  filter(word == "developer") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

experience_in_headline <- word_count %>% 
  filter(word == "experience") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

engineer_in_headline <- word_count %>% 
  filter(word == "engineer") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

senior_in_headline <- word_count %>% 
  filter(word == "senior") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

position_in_headline <- word_count %>% 
  filter(word == "position") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

experienced_in_headline <- word_count %>% 
  filter(word == "experienced") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

fullstack_in_headline <- word_count %>% 
  filter(word == "fullstack") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

java_in_headline <- word_count %>% 
  filter(word == "java") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

backend_in_headline <- word_count %>% 
  filter(word == "backend") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

frontend_in_headline <- word_count %>% 
  filter(word == "frontend") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

javascript_in_headline <- word_count %>% 
  filter(word == "javascript") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

python_in_headline <- word_count %>% 
  filter(word == "python") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

software_in_headline <- word_count %>% 
  filter(word == "software") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

php_in_headline <- word_count %>% 
  filter(word == "php") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

lead_in_headline <- word_count %>% 
  filter(word == "lead") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

ruby_in_headline <- word_count %>% 
  filter(word == "ruby") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

opportunity_in_headline <- word_count %>% 
  filter(word == "opportunity") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

berlin_in_headline <- word_count %>% 
  filter(word == "berlin") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

data_in_headline <- word_count %>% 
  filter(word == "data") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

team_in_headline <- word_count %>% 
  filter(word == "team") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

no_developer_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "developer"), by = "talent_id")

no_experience_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "experience"), by = "talent_id")

no_engineer_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "engineer"), by = "talent_id")

no_senior_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "senior"), by = "talent_id")

no_position_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "position"), by = "talent_id")

no_experienced_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "experienced"), by = "talent_id")

no_fullstack_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "fullstack"), by = "talent_id")

no_java_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "java"), by = "talent_id")

no_backend_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "backend"), by = "talent_id")

no_frontend_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "frontend"), by = "talent_id")

no_javascript_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "javascript"), by = "talent_id")

no_python_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "python"), by = "talent_id")

no_software_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "software"), by = "talent_id")

no_php_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "php"), by = "talent_id")

no_lead_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "lead"), by = "talent_id")

no_ruby_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "ruby"), by = "talent_id")

no_opportunity_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "opportunity"), by = "talent_id")

no_berlin_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "berlin"), by = "talent_id")

no_data_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "data"), by = "talent_id")

no_team_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "team"), by = "talent_id")
  
no_developer_in_headline %>% 
  filter(interview_invites > 0) 

no_experience_in_headline %>% 
  filter(interview_invites > 0)

no_engineer_in_headline %>% 
  filter(interview_invites > 0)

no_senior_in_headline %>% 
  filter(interview_invites > 0)

no_position_in_headline %>% 
  filter(interview_invites > 0)

B_top_20_words <- most_20_words [1:20,] %>% 
  mutate("used_invite" = c(
    nrow(developer_in_headline), 
    nrow(experience_in_headline), 
    nrow(engineer_in_headline), 
    nrow(senior_in_headline), 
    nrow(position_in_headline), 
    nrow(experienced_in_headline),
    nrow(fullstack_in_headline), 
    nrow(java_in_headline),
    nrow(backend_in_headline),
    nrow(frontend_in_headline),
    nrow(javascript_in_headline),
    nrow(python_in_headline),
    nrow(software_in_headline),
    nrow(php_in_headline),
    nrow(lead_in_headline),
    nrow(ruby_in_headline),
    nrow(opportunity_in_headline),
    nrow(berlin_in_headline),
    nrow(data_in_headline),
    nrow(team_in_headline)
    
    ),
    
    
    "total_not_used" = c(
    nrow(no_developer_in_headline), 
    nrow(no_experience_in_headline), 
    nrow(no_engineer_in_headline), 
    nrow(no_senior_in_headline), 
    nrow(no_position_in_headline), 
    nrow(no_experienced_in_headline), 
    nrow(no_fullstack_in_headline),
    nrow(no_java_in_headline),
    nrow(no_backend_in_headline),
    nrow(no_frontend_in_headline),
    nrow(no_javascript_in_headline),
    nrow(no_python_in_headline),
    nrow(no_software_in_headline),
    nrow(no_php_in_headline),
    nrow(no_lead_in_headline),
    nrow(no_ruby_in_headline),
    nrow(no_opportunity_in_headline),
    nrow(no_berlin_in_headline),
    nrow(no_data_in_headline),
    nrow(no_team_in_headline)
    
    ), 
    "total_not_used_invited" = c(
    nrow(filter(no_developer_in_headline, interview_invites > 0)), 
    nrow(filter(no_experience_in_headline, interview_invites > 0)), 
    nrow(filter(no_engineer_in_headline, interview_invites > 0)), 
    nrow(filter(no_senior_in_headline, interview_invites > 0)), 
    nrow(filter(no_position_in_headline, interview_invites > 0)),
    nrow(filter(no_experienced_in_headline, interview_invites > 0)),
    nrow(filter(no_fullstack_in_headline, interview_invites > 0)),
    nrow(filter(no_java_in_headline, interview_invites > 0)),
    nrow(filter(no_backend_in_headline, interview_invites > 0)),
    nrow(filter(no_frontend_in_headline, interview_invites > 0)),
    nrow(filter(no_javascript_in_headline, interview_invites > 0)),
    nrow(filter(no_python_in_headline, interview_invites > 0)),
    nrow(filter(no_software_in_headline, interview_invites > 0)),
    nrow(filter(no_php_in_headline, interview_invites > 0)),
    nrow(filter(no_lead_in_headline, interview_invites > 0)),
    nrow(filter(no_ruby_in_headline, interview_invites > 0)),
    nrow(filter(no_opportunity_in_headline, interview_invites > 0)),
    nrow(filter(no_berlin_in_headline, interview_invites > 0)),
    nrow(filter(no_data_in_headline, interview_invites > 0)),
    nrow(filter(no_team_in_headline, interview_invites > 0))
      
      ))




B_top_20_words <-  B_top_20_words %>% 
  mutate("perC_used_invite" = used_invite / n, "perC_not_used_invite" = total_not_used_invited / total_not_used, "Impact"=(perC_used_invite / perC_not_used_invite - 1)*100)

B_top_20_words%>% 
  ggplot(aes(x = word, y = Impact, fill= Impact)) +
  geom_col()+
  theme(text = element_text(size=20), axis.text.x = element_text(angle=90, hjust=1),legend.position="none")+
  ggtitle("Impact of Words on Invite Rate")+
  ylab("Impact in %")+
  xlab("Word")

  
B_top_20_words%>% 
  ggplot(aes(x = word, y = perC_used_invite*100,fill = perC_used_invite)) +
  geom_col()+
  theme(text = element_text(size=20), axis.text.x = element_text(angle=90, hjust=1),legend.position="none")+
  ylab("Interview Invites in %")+
  xlab("Word")

B_top_5_words <- most_20_words[1:5,] %>% 
  mutate("used_invite" = c(nrow(developer_in_headline), nrow(experience_in_headline), nrow(engineer_in_headline), nrow(senior_in_headline), nrow(position_in_headline)), "total_not_used" = c(nrow(no_developer_in_headline), nrow(no_experience_in_headline), nrow(no_engineer_in_headline), nrow(no_senior_in_headline), nrow(no_position_in_headline)), "total_not_used_invited" = c(nrow(filter(no_developer_in_headline, interview_invites > 0)), nrow(filter(no_experience_in_headline, interview_invites > 0)), nrow(filter(no_engineer_in_headline, interview_invites > 0)), nrow(filter(no_senior_in_headline, interview_invites > 0)), nrow(filter(no_position_in_headline, interview_invites > 0))))

B_top_5_words <-  B_top_5_words %>% 
  mutate("%_used_invite" = used_invite / n, "%_not_used_invite" = total_not_used_invited / total_not_used)

B_top_5_words %>% 
  ggplot(aes(x = word, y = "%_used_invite", fill = used_invite)) +
  geom_col()
  

```

```{r}
hire_developer_in_headline <- word_count %>% 
  filter(word == "developer") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_experience_in_headline <- word_count %>% 
  filter(word == "experience") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_engineer_in_headline <- word_count %>% 
  filter(word == "engineer") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_senior_in_headline <- word_count %>% 
  filter(word == "senior") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_position_in_headline <- word_count %>% 
  filter(word == "position") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_experienced_in_headline <- word_count %>% 
  filter(word == "experienced") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_fullstack_in_headline <- word_count %>% 
  filter(word == "fullstack") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_java_in_headline <- word_count %>% 
  filter(word == "java") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_backend_in_headline <- word_count %>% 
  filter(word == "backend") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_frontend_in_headline <- word_count %>% 
  filter(word == "frontend") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_javascript_in_headline <- word_count %>% 
  filter(word == "javascript") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_python_in_headline <- word_count %>% 
  filter(word == "python") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_software_in_headline <- word_count %>% 
  filter(word == "software") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_php_in_headline <- word_count %>% 
  filter(word == "php") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_lead_in_headline <- word_count %>% 
  filter(word == "lead") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_ruby_in_headline <- word_count %>% 
  filter(word == "ruby") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_opportunity_in_headline <- word_count %>% 
  filter(word == "opportunity") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_berlin_in_headline <- word_count %>% 
  filter(word == "berlin") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_data_in_headline <- word_count %>% 
  filter(word == "data") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_team_in_headline <- word_count %>% 
  filter(word == "team") %>% 
  inner_join(talents) %>% 
  filter(was_hired == 1)

hire_no_developer_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "developer"), by = "talent_id")

hire_no_experience_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "experience"), by = "talent_id")

hire_no_engineer_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "engineer"), by = "talent_id")

hire_no_senior_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "senior"), by = "talent_id")

hire_no_position_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "position"), by = "talent_id")

hire_no_experienced_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "experienced"), by = "talent_id") 

hire_no_fullstack_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "fullstack"), by = "talent_id") 

hire_no_java_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "java"), by = "talent_id") 

hire_no_backend_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "backend"), by = "talent_id") 

hire_no_frontend_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "frontend"), by = "talent_id") 

hire_no_javascript_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "javascript"), by = "talent_id") 

hire_no_python_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "python"), by = "talent_id") 

hire_no_software_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "software"), by = "talent_id")

hire_no_php_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "php"), by = "talent_id")

hire_no_lead_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "lead"), by = "talent_id")

hire_no_ruby_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "ruby"), by = "talent_id")

hire_no_opportunity_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "opportunity"), by = "talent_id")

hire_no_berlin_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "berlin"), by = "talent_id")

hire_no_data_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "data"), by = "talent_id")

hire_no_team_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "team"), by = "talent_id")




C_hire_words <- most_20_words [1:20,] %>% 
  mutate("used_invite" = c(
    nrow(hire_developer_in_headline), 
    nrow(hire_experience_in_headline), 
    nrow(hire_engineer_in_headline), 
    nrow(hire_senior_in_headline), 
    nrow(hire_position_in_headline), 
    nrow(hire_experienced_in_headline),
    nrow(hire_fullstack_in_headline), 
    nrow(hire_java_in_headline),
    nrow(hire_backend_in_headline),
    nrow(hire_frontend_in_headline),
    nrow(hire_javascript_in_headline),
    nrow(hire_python_in_headline),
    nrow(hire_software_in_headline),
    nrow(hire_php_in_headline),
    nrow(hire_lead_in_headline),
    nrow(hire_ruby_in_headline),
    nrow(hire_opportunity_in_headline),
    nrow(hire_berlin_in_headline),
    nrow(hire_data_in_headline),
    nrow(hire_team_in_headline)
    
    ),
    
    
    "total_not_used" = c(
    nrow(hire_no_developer_in_headline), 
    nrow(hire_no_experience_in_headline), 
    nrow(hire_no_engineer_in_headline), 
    nrow(hire_no_senior_in_headline), 
    nrow(hire_no_position_in_headline), 
    nrow(hire_no_experienced_in_headline), 
    nrow(hire_no_fullstack_in_headline),
    nrow(hire_no_java_in_headline),
    nrow(hire_no_backend_in_headline),
    nrow(hire_no_frontend_in_headline),
    nrow(hire_no_javascript_in_headline),
    nrow(hire_no_python_in_headline),
    nrow(hire_no_software_in_headline),
    nrow(hire_no_php_in_headline),
    nrow(hire_no_lead_in_headline),
    nrow(hire_no_ruby_in_headline),
    nrow(hire_no_opportunity_in_headline),
    nrow(hire_no_berlin_in_headline),
    nrow(hire_no_data_in_headline),
    nrow(hire_no_team_in_headline)
    
    ), 
    "total_not_used_invited" = c(
    nrow(filter(hire_no_developer_in_headline, was_hired == 1)), 
    nrow(filter(hire_no_experience_in_headline, was_hired == 1)), 
    nrow(filter(hire_no_engineer_in_headline, was_hired == 1)), 
    nrow(filter(hire_no_senior_in_headline, was_hired == 1)), 
    nrow(filter(hire_no_position_in_headline, was_hired == 1)),
    nrow(filter(hire_no_experienced_in_headline, was_hired == 1)),
    nrow(filter(hire_no_fullstack_in_headline, was_hired == 1)),
    nrow(filter(hire_no_java_in_headline, was_hired == 1)),
    nrow(filter(hire_no_backend_in_headline, was_hired == 1)),
    nrow(filter(hire_no_frontend_in_headline, was_hired == 1)),
    nrow(filter(hire_no_javascript_in_headline, was_hired == 1)),
    nrow(filter(hire_no_python_in_headline, was_hired == 1)),
    nrow(filter(hire_no_software_in_headline, was_hired == 1)),
    nrow(filter(hire_no_php_in_headline, was_hired == 1)),
    nrow(filter(hire_no_lead_in_headline, was_hired == 1)),
    nrow(filter(hire_no_ruby_in_headline, was_hired == 1)),
    nrow(filter(hire_no_opportunity_in_headline, was_hired == 1)),
    nrow(filter(hire_no_berlin_in_headline, was_hired == 1)),
    nrow(filter(hire_no_data_in_headline, was_hired == 1)),
     nrow(filter(hire_no_team_in_headline, was_hired == 1))
      
      ))




C_hire_words <-  C_hire_words %>% 
  mutate("perC_used_invite" = used_invite / n, "perC_not_used_invite" = total_not_used_invited / total_not_used, "Impact"=(perC_used_invite / perC_not_used_invite - 1)*100)

C_hire_words%>% 
  ggplot(aes(x = word, y = Impact, fill= Impact)) +
  geom_col()+
  theme(text = element_text(size=20), axis.text.x = element_text(angle=90, hjust=1),legend.position="none")+
  ylab("Impact in %")+
  xlab("Word")

  
C_hire_words%>% 
  ggplot(aes(x = word, y = perC_used_invite*100,fill = perC_used_invite)) +
  geom_col()+
  theme(text = element_text(size=20), axis.text.x = element_text(angle=90, hjust=1),legend.position="none")+
  ylab("Hired in %")+
  xlab("Word")

```

```{r}
# Analyzing word and document frequency: tf-idf
# Find important words through bind_tf_idf
# the numbers are not very meaningful. Maybe they would be better if all headlines for a work_role are grouped and analyzed into one big headline.
# what worked was to get words which were oftent used in combination with a given word
# print out a ggraph didnt work

headlines_bigrams <- headlines_df %>%
  unnest_tokens(bigram, headline, token = "ngrams", n = 2)

headlines_bigrams %>%
  count_("bigram", sort = TRUE) %>% 
  View()

library(tidyr)

bigrams_separated <- headlines_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts:
bigram_counts <- bigrams_filtered %>% 
  dplyr::count(word1, word2)

bigram_counts

bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")

bigrams_united

bigrams_filtered %>%
  dplyr::filter(word2 == "developer") %>%
  dplyr::count(talent_id, word1, sort = TRUE) %>% 
  View()

developer_types <- bigrams_filtered %>%
  dplyr::filter(word2 == "developer") %>%
  dplyr::count(talent_id, word1, sort = TRUE) %>% 
  group_by(word1) %>% 
  dplyr::count_() %>% 
  arrange(-nn)

developer_types[1:10,] %>% 
  ggplot(aes(x = reorder(word1, -nn), y = nn)) +
  geom_col() +
  xlab("Häufigst erwähnte Wörter im Zusammenhang mit developer") +
  ylab("n")

#install.packages("igraph")
library(igraph)

# original counts
bigram_counts

bigram_graph <- bigram_counts %>%
  filter(n > 20) %>%
  graph_from_data_frame()

bigram_graph

#install.packages("ggraph")
library(ggraph)
set.seed(2017)

ggraph::ggraph(bigram_graph, layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)
```


```{r}
# top 5 Wörter der work_roles
with_headlines_work_roles <- with_headlines %>% 
  filter(work_roles != "{}")

# Anzahl der vertretenen workroles ermittelt
with_headlines_work_roles %>% 
  group_by(work_roles) %>% 
  count_("work_roles") %>% 
  arrange(-n) %>% 
  View()

#-----
with_headlines_backend_fullstack <- with_headlines %>% 
  filter(work_roles == "{Backend,Fullstack}")

headlines_backend_fullstack_df <- data_frame(talent_id = with_headlines_backend_fullstack$talent_id, headline = as.vector(with_headlines_backend_fullstack$headline))

# split a headline (one row per headline) to one word per row with corresponding talent_id
unnested_headlines_backend_fullstack <- headlines_backend_fullstack_df %>%
  unnest_tokens(word, headline)

#
unnested_headlines_backend_fullstack <- unnested_headlines_backend_fullstack %>%
  # delete stop words
  anti_join(stop_words) %>%
  # Group by each word
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)

#top 5 Wörter in backend_fullstack
unnested_headlines_backend_fullstack[1:5,] %>% 
  View()

#-----
with_headlines_backend <- with_headlines %>% 
  filter(work_roles == "{Backend}")

headlines_backend_df <- data_frame(talent_id = with_headlines_backend$talent_id, headline = as.vector(with_headlines_backend$headline))

# split a headline (one row per headline) to one word per row with corresponding talent_id
unnested_headlines_backend <- headlines_backend_df %>%
  unnest_tokens(word, headline)

#
unnested_headlines_backend <- unnested_headlines_backend %>%
  # delete stop words
  anti_join(stop_words) %>%
  # Group by each word
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)

#top 5 Wörter in backend
unnested_headlines_backend[1:5,] %>% 
  View()

#-----
with_headlines_frontend <- with_headlines %>% 
  filter(work_roles == "{Frontend}")

headlines_frontend_df <- data_frame(talent_id = with_headlines_frontend$talent_id, headline = as.vector(with_headlines_frontend$headline))

# split a headline (one row per headline) to one word per row with corresponding talent_id
unnested_headlines_frontend <- headlines_frontend_df %>%
  unnest_tokens(word, headline)

#
unnested_headlines_frontend <- unnested_headlines_frontend %>%
  # delete stop words
  anti_join(stop_words) %>%
  # Group by each word
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)

#top 5 Wörter in frontend
unnested_headlines_frontend[1:5,] %>% 
  View()

#-----
with_headlines_mobile <- with_headlines %>% 
  filter(work_roles == "{Mobile}")

headlines_mobile_df <- data_frame(talent_id = with_headlines_mobile$talent_id, headline = as.vector(with_headlines_mobile$headline))

# split a headline (one row per headline) to one word per row with corresponding talent_id
unnested_headlines_mobile <- headlines_mobile_df %>%
  unnest_tokens(word, headline)

#
unnested_headlines_mobile <- unnested_headlines_mobile %>%
  # delete stop words
  anti_join(stop_words) %>%
  # Group by each word
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)

#top 5 Wörter in mobile
unnested_headlines_mobile[1:5,] %>% 
  View()
  
#-----
with_headlines_frontend_fullstack <- with_headlines %>% 
  filter(work_roles == "{Frontend,Fullstack}")

headlines_frontend_fullstack_df <- data_frame(talent_id = with_headlines_frontend_fullstack$talent_id, headline = as.vector(with_headlines_frontend_fullstack$headline))

# split a headline (one row per headline) to one word per row with corresponding talent_id
unnested_headlines_frontend_fullstack <- headlines_frontend_fullstack_df %>%
  unnest_tokens(word, headline)

#
unnested_headlines_frontend_fullstack <- unnested_headlines_frontend_fullstack %>%
  # delete stop words
  anti_join(stop_words) %>%
  # Group by each word
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)

#top 5 Wörter in frontend fullstack
unnested_headlines_frontend_fullstack[1:5,] %>% 
  View()

#---- gesamtübersicht top 5 work roles

top_5_words_per_work_role <- data_frame("{Backend,Fullstack}" = unnested_headlines_backend_fullstack$word[1:5],"{Backend,Fullstack} n" = unnested_headlines_backend_fullstack$n[1:5], "{Backend}" = unnested_headlines_backend$word[1:5], "{Backend} n" = unnested_headlines_backend$n[1:5], "{Frontend}" = unnested_headlines_frontend$word[1:5], "{Frontend} n" = unnested_headlines_frontend$n[1:5],  "{Mobile}" = unnested_headlines_mobile$word[1:5], "{Mobile} n" = unnested_headlines_mobile$n[1:5], "{Frontend,Fullstack}" = unnested_headlines_frontend_fullstack$word[1:5],  "{Frontend,Fullstack} n" = unnested_headlines_frontend_fullstack$n[1:5])

#backend fullstack
unnested_headlines_backend_fullstack[1:5,] %>% 
  ggplot(aes(x = word, y = n)) +
  geom_col() 

#backend 
unnested_headlines_backend[1:5,] %>% 
  ggplot(aes(x = word, y = n)) +
  geom_col() 

#frontend
unnested_headlines_frontend[1:5,] %>% 
  ggplot(aes(x = word, y = n)) +
  geom_col()

#mobile
unnested_headlines_mobile[1:5,] %>% 
  ggplot(aes(x = word, y = n)) +
  geom_col() 

#frontend fullstack
unnested_headlines_frontend_fullstack[1:5,] %>% 
  ggplot(aes(x = word, y = n)) +
  geom_col() 

```

```{r}
#install.packages("scales")
#install.packages("zoo")

library(scales)
library(zoo)


# welche wörter waren die 5 meist verwendetsten pro monat
batches$created_at <- as.Date(batches$created_at)

batches$month_year <- as.yearmon(batches$created_at)

batches %>% 
  left_join(unnested_headlines) %>% 
  anti_join(stop_words) %>% 
  group_by(month_year) %>% 
  count_("word") %>% 
  View()

View(batches)




B_batches_over_time <- batches %>% 
  group_by(batch_id) %>% 
  count_()

ggplot(B_batches_over_time, aes(x = batch_id, y = n, fill=n)) + 
  geom_line()+
  ylab("Amount of Talents batched")+
  xlab("Batch ID")+
  theme(legend.position = "none")

# Erkenntnis!!!!!: was_batched ist inkonsistent, es gibt mehr gebatchete talents in der baches.csv

talent_id_and_count_error_was_batched <- batches %>% 
  left_join(unnested_headlines) %>% 
  left_join(talents) %>%
  filter(was_batched == 0) %>% 
  group_by(talent_id) %>% 
  count_() %>% 
  View()

error_was_batched <- batches %>% 
  left_join(unnested_headlines) %>% 
  left_join(talents) %>%
  filter(was_batched == 0) %>% 
  group_by(talent_id) %>% 
  count_() %>% 
  nrow()

talents

#TODO
#ggplot colchart/barchar bar 1 count was_batched // bar 2 was batched in batches aber was_batched == 0
# eventuell noch talents korrigieren
# um gebatched zu werden brauch man eine headline


data_frame( was_bached = c("talents","batches"), n = c(nrow(with_headlines_was_batched), error_was_batched + nrow(with_headlines_was_batched))) %>% 
  ggplot(aes(x = was_bached, y = n)) +
  geom_col()

batches %>% 
  left_join(unnested_headlines) %>% 
  anti_join(stop_words) %>% 
  group_by(month_year, word) %>% 
  count_() %>% 
  View()
  
talents %>% 
  filter(was_batched == 0, headline != "")

ggplot(batches, aes(x = month_year)) +
  geom_bar()

str(batches)
```


Wordcloud
```{r}
wordcloud(unnested_headlines_total$word[1:200], unnested_headlines_total$n[1:200])

```


headline vs !headline
```{r}
#
with_headlines_was_batched <- with_headlines %>% 
  filter(was_batched == 1)  

# 7 wurden gebatched ohne headline
without_headlines_was_batched <- without_headlines %>% 
  filter(was_batched == 1) 

with_headlines_was_hired <- with_headlines %>% 
  filter(was_hired == 1)

without_headlines_was_hired <- without_headlines %>% 
  filter(was_hired == 1)

# um gebatched zu werden brauch man eine headline
data_frame( headline = c("headline","no headline"), n = c(nrow(with_headlines_was_batched), nrow(without_headlines_was_batched))) %>% 
  ggplot(aes(x = headline, y = n)) +
  geom_col()+
  ggtitle("Batched Talents")+
  ylab("Count")+
  xlab("Headline")

# um gehired zu werden muss man gebatched werden (ausnahme von 9)
data_frame( headline = rev(c("was_not_batched","was_batched")), n = c(nrow(with_headlines_was_hired), nrow(without_headlines_was_hired))) %>% 
  ggplot(aes(x = headline, y = n)) +
  geom_col()+
  ggtitle("Hired Talents")+
  ylab("Count")+
  xlab("Hired")

# Ausnahmen: 9 wurden gehired ohne batch
was_hired_without_batched <- talents %>% 
  filter(was_hired == 1, was_batched == 0)


headlines_df_was_hired <- data_frame(talent_id = filter(with_headlines, was_hired == 1)$talent_id, headline = as.vector(filter(with_headlines, was_hired == 1)$headline))

unnested_headlines_was_hired <- headlines_df_was_hired %>%
  unnest_tokens(word, headline) %>% 
  anti_join(stop_words) %>% 
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)

unnested_headlines_total <- headlines_df %>%
  unnest_tokens(word, headline) %>% 
  anti_join(stop_words) %>% 
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)
# Versuch jedem Wort eine Wahrscheinlichkeit zuordnen die zum hired führt
hired_words_propability <- inner_join(unnested_headlines_was_hired, unnested_headlines_total, by = "word")

colnames(hired_words_propability) <- c("word", "n_hired", "n_total")

hired_words_propability <- hired_words_propability %>% 
  mutate(propability = n_hired / n_total )


# ----------------------------------------------------
developer_talents <- unnested_headlines %>% 
  filter(word == "developer") %>% 
  group_by(talent_id) %>% 
  count_() %>% 
  arrange(-n)

developer_talents <- developer_talents %>% 
  inner_join(talents)

summary(developer_talents)

#TODO
# Workexperience headline vs workexperience developer
developer_talents_workexperience <- developer_talents %>% 
  group_by(work_experience) %>% 
  count_()

talents_workexperience <- talents %>% 
  group_by(work_experience) %>% 
  count_()

developer_talents_workexperience <- developer_talents_workexperience %>% 
  filter(work_experience != "") %>% 
  mutate(verhaeltnis = nn/sum(nn))

talents_workexperience <- talents_workexperience %>% 
  filter(work_experience != "", n != 1) %>% 
  mutate(verhaeltnis = n/sum(n))

colnames(developer_talents_workexperience) <- c("work_experience", "n_developer", "verhältnis_developer")

joined_work_experience <- inner_join(developer_talents_workexperience, talents_workexperience)

ggplot(joined_work_experience, aes(x = work_experience, y = verhältnis_developer)) +
geom_col()

# Workexperience hired 
# workexperience total vs workexperience hired 

```


DATA ANALYZATION

Batches

```{r}
#overview of batches
summary(batches)
batches
#ID starts at 9, why? 

# amount of times batched per talent_id hi-lo
batches%>%
  count("talent_id")%>%
arrange(-freq)


```

Salaries

```{r}
# overview of salaries
summary(salaries)

#order by talents hired by city  hi-lo
salaries%>%
    group_by(city) %>%
  summarise(n=n()) %>% 
  arrange(-n)  
#avg min salary per city
salaries%>%
    group_by(city) %>%
summarise(average_sal_min=mean(minimum,na.rm=TRUE)) %>%  
  arrange(-average_sal_min)


#avg max slary per city
salaries%>%
    group_by(city) %>%
summarise(average_sal_max=mean(maximum,na.rm=TRUE)) %>%  
  arrange(-average_sal_max)


```

Talents

```{r}
summary(talents)



talents <- HWR_DATA_talents_subset %>% 
  filter(grepl('AngularJS',headline) & was_hired %in% '1') %>% 
  filter(grepl("\\d",headline) | grepl("\\w",headline))

# Hired Rate ?!?! no_headline <- talents %>% select(grepl("\\d",headline) | !grepl("\\w",headline))




summary(no_headline)

```

```{r}

```

```{r}
 
# MOST USED WORDS IN HEADLINES   (source: https://www.tidytextmining.com/tidytext.html#the-unnest_tokens-function)
# turn headlines into C(Stings)
hltext <- c(toString(talents$headline))

library(dplyr) 
#putting all strings in one line
text_df <- data_frame(line = 1:1, text = hltext)

library(ggplot2)
#create new data "countwords" for text mining
countwords <- text_df%>%
#seperating 1 word per line
unnest_tokens(word,text)%>%
#remove common words like "a". "and" etc.
anti_join(stop_words)%>%
#count each word
count(word, sort = TRUE) 

countwords%>%
#filter words that accure at least twice
filter(n > 2) %>%
mutate(word = reorder(word, n)) %>%
#plot graph
ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```
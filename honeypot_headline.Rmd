---
title: "Headline"
author: "Tino Wagner"
date: "6 Juni 2018"
output: html_document
---

PREPERATION

```{r}
#install/load packages: tidyvers, tidytext
#install.packages("magrittr")
#install.packages("tidyverse")
#install.packages("tidytext")
#install.packages("wordcloud")
library(tidyverse)
library(tidytext)
library(magrittr)
library(plyr)
library(dplyr)
library(ggplot2)
library(wordcloud)

#import data sets
batches <- read.csv("./Honeypot_subset/HWR_DATA_batches_subset.csv")
salaries <- read.csv("./Honeypot_subset/HWR_DATA_salaries_subset.csv")
talents <- read.csv("./Honeypot_subset/HWR_DATA_talents_subset.csv")

```

Text Mining
```{r}
# filter for talents with a headline
with_headlines <- talents %>% 
  filter(talents$headline != "")

# filter for talents without a headline
without_headlines <- talents %>% 
  filter(talents$headline == "")

# Dataframe with talen_id and headline
headlines_df <- data_frame(talent_id = with_headlines$talent_id, headline = as.vector(with_headlines$headline))

# split a headline (one row per headline) to one word per row with corresponding talent_id
unnested_headlines <- headlines_df %>%
  unnest_tokens(word, headline)

# word count
word_count <- unnested_headlines %>%
  # delete stop words
  anti_join(stop_words) %>%
  # Group by each word
  group_by(talent_id ,word) %>% 
  count_() %>% 
  arrange(-n)
  
word_count_per_talent_id <- word_count %>% 
  group_by(word) %>% 
  count_() %>% 
  arrange(-nn)

colnames(word_count_per_talent_id) <- c("word", "n")

# number of words used per talent_id
word_count_per_headline <- unnested_headlines %>%
  # delete stop words
  anti_join(stop_words) %>%
  # Group by each word
  group_by(talent_id) %>% 
  count_() %>% 
  arrange(-n)

# refactor levels of word in word_count_per_talent_id
word_count_per_talent_id$word <- factor(word_count_per_talent_id$word, levels = word_count_per_talent_id$word)

# new data frame with most used 20 words
most_20_words <- data_frame(word = word_count_per_talent_id$word[1:20], n = word_count_per_talent_id$n[1:20])
# add all other words aggregated as "Other words" with their count
most_20_words <- rbind(most_20_words, data.frame(word = "Other words", n = sum(word_count_per_talent_id$n[21:length(word_count_per_talent_id)])))
#refactor levels
most_20_words$word <- factor(most_20_words$word, levels = most_20_words$word)

# plot word count most used 20 words and other words
most_20_words %>% 
  ggplot(aes(x = word, y = n)) +
  geom_col()

# 12060 were invited_to_call
invited_to_call <- talents %>% 
  filter(invited_to_call == 1)

talents %>%
  filter(was_batched == 1, interview_invites != 0) %>% 
  count_()

talents %>% 
  filter(was_hired == 1) %>% 
  count_()

# Wort auftreten in batched und !Wort in batched
was_batched <- talents %>% 
  filter(was_batched == 1) %>% 
  left_join(word_count)

was_batched <- was_batched[c("talent_id", "word", "n")]

was_batched <- was_batched %>% 
  count_("word") %>% 
  arrange(-nn) %>% 
  mutate("propability" = nn / was_batched %>% 
           group_by(talent_id) %>% 
           count_() %>% 
           nrow()
         )

colnames(was_batched) <- c("word", "n_was_bached", "propability_was_bached")

#id die gebached wurden in develop benutzen
#Anzahl der Leute die gebatched wurden und developer in der headline haben
word_count %>% 
  filter(word == "developer") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0) %>% 
  nrow() %>% 
  View()

#Anzahl der Leute die gebatched wurden und !developer in der headline haben
developer_in_headline <- word_count %>% 
  filter(word == "developer") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

experience_in_headline <- word_count %>% 
  filter(word == "experience") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

engineer_in_headline <- word_count %>% 
  filter(word == "engineer") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

senior_in_headline <- word_count %>% 
  filter(word == "senior") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

position_in_headline <- word_count %>% 
  filter(word == "position") %>% 
  inner_join(talents) %>% 
  filter(interview_invites > 0)

no_developer_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "developer"), by = "talent_id")

no_experience_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "experience"), by = "talent_id")

no_engineer_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "engineer"), by = "talent_id")

no_senior_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "senior"), by = "talent_id")

no_position_in_headline <- with_headlines %>% 
  anti_join(filter(word_count, word == "position"), by = "talent_id")
  
no_developer_in_headline %>% 
  filter(interview_invites > 0) 

no_experience_in_headline %>% 
  filter(interview_invites > 0)

no_engineer_in_headline %>% 
  filter(interview_invites > 0)

no_senior_in_headline %>% 
  filter(interview_invites > 0)

no_position_in_headline %>% 
  filter(interview_invites > 0)

"1_top_5_words" <- most_20_words[1:5,] %>% 
  mutate("used_invite" = c(nrow(developer_in_headline), nrow(experience_in_headline), nrow(engineer_in_headline), nrow(senior_in_headline), nrow(position_in_headline)), "total_not_used" = c(nrow(no_developer_in_headline), nrow(no_experience_in_headline), nrow(no_engineer_in_headline), nrow(no_senior_in_headline), nrow(no_position_in_headline)), "total_not_used_invited" = c(nrow(filter(no_developer_in_headline, interview_invites > 0)), nrow(filter(no_experience_in_headline, interview_invites > 0)), nrow(filter(no_engineer_in_headline, interview_invites > 0)), nrow(filter(no_senior_in_headline, interview_invites > 0)), nrow(filter(no_position_in_headline, interview_invites > 0))))

`1_top_5_words` <-  `1_top_5_words` %>% 
  mutate("%_used_invite" = used_invite / n, "%_not_used_invite" = total_not_used_invited / total_not_used)

`1_top_5_words` %>% 
  ggplot(aes(x = word, y = "%_used_invite", fill = used_invite)) +
  geom_col()
  

```

```{r}
# Analyzing word and document frequency: tf-idf
# Find important words through bind_tf_idf
# the numbers are not very meaningful. Maybe they would be better if all headlines for a work_role are grouped and analyzed into one big headline.
# what worked was to get words which were oftent used in combination with a given word

headlines_bigrams <- headlines_df %>%
  unnest_tokens(bigram, headline, token = "ngrams", n = 2)

headlines_bigrams %>%
  count_("bigram", sort = TRUE) %>% 
  View()

library(tidyr)

bigrams_separated <- headlines_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts:
bigram_counts <- bigrams_filtered %>% 
  dplyr::count(word1, word2)

bigram_counts

bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")

bigrams_united

bigrams_filtered %>%
  dplyr::filter(word2 == "developer") %>%
  dplyr::count(talent_id, word1, sort = TRUE) %>% 
  View()

developer_types <- bigrams_filtered %>%
  dplyr::filter(word2 == "developer") %>%
  dplyr::count(talent_id, word1, sort = TRUE) %>% 
  group_by(word1) %>% 
  dplyr::count_() %>% 
  arrange(-nn)

developer_types[1:10,] %>% 
  ggplot(aes(x = reorder(word1, -nn), y = nn)) +
  geom_col() +
  xlab("Häufigst erwähnte Wörter im Zusammenhang mit developer") +
  ylab("n")

#install.packages("igraph")
library(igraph)

# original counts
bigram_counts

bigram_graph <- bigram_counts %>%
  filter(n > 20) %>%
  graph_from_data_frame()

bigram_graph

#install.packages("ggraph")
library(ggraph)
set.seed(2017)

ggraph::ggraph(bigram_graph, layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)
```


```{r}
# top 5 Wörter der work_roles
with_headlines_work_roles <- with_headlines %>% 
  filter(work_roles != "{}")

# Anzahl der vertretenen workroles ermittelt
with_headlines_work_roles %>% 
  group_by(work_roles) %>% 
  count_("work_roles") %>% 
  arrange(-n) %>% 
  View()

#-----
with_headlines_backend_fullstack <- with_headlines %>% 
  filter(work_roles == "{Backend,Fullstack}")

headlines_backend_fullstack_df <- data_frame(talent_id = with_headlines_backend_fullstack$talent_id, headline = as.vector(with_headlines_backend_fullstack$headline))

# split a headline (one row per headline) to one word per row with corresponding talent_id
unnested_headlines_backend_fullstack <- headlines_backend_fullstack_df %>%
  unnest_tokens(word, headline)

#
unnested_headlines_backend_fullstack <- unnested_headlines_backend_fullstack %>%
  # delete stop words
  anti_join(stop_words) %>%
  # Group by each word
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)

#top 5 Wörter in backend_fullstack
unnested_headlines_backend_fullstack[1:5,] %>% 
  View()

#-----
with_headlines_backend <- with_headlines %>% 
  filter(work_roles == "{Backend}")

headlines_backend_df <- data_frame(talent_id = with_headlines_backend$talent_id, headline = as.vector(with_headlines_backend$headline))

# split a headline (one row per headline) to one word per row with corresponding talent_id
unnested_headlines_backend <- headlines_backend_df %>%
  unnest_tokens(word, headline)

#
unnested_headlines_backend <- unnested_headlines_backend %>%
  # delete stop words
  anti_join(stop_words) %>%
  # Group by each word
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)

#top 5 Wörter in backend
unnested_headlines_backend[1:5,] %>% 
  View()

#-----
with_headlines_frontend <- with_headlines %>% 
  filter(work_roles == "{Frontend}")

headlines_frontend_df <- data_frame(talent_id = with_headlines_frontend$talent_id, headline = as.vector(with_headlines_frontend$headline))

# split a headline (one row per headline) to one word per row with corresponding talent_id
unnested_headlines_frontend <- headlines_frontend_df %>%
  unnest_tokens(word, headline)

#
unnested_headlines_frontend <- unnested_headlines_frontend %>%
  # delete stop words
  anti_join(stop_words) %>%
  # Group by each word
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)

#top 5 Wörter in frontend
unnested_headlines_frontend[1:5,] %>% 
  View()

#-----
with_headlines_mobile <- with_headlines %>% 
  filter(work_roles == "{Mobile}")

headlines_mobile_df <- data_frame(talent_id = with_headlines_mobile$talent_id, headline = as.vector(with_headlines_mobile$headline))

# split a headline (one row per headline) to one word per row with corresponding talent_id
unnested_headlines_mobile <- headlines_mobile_df %>%
  unnest_tokens(word, headline)

#
unnested_headlines_mobile <- unnested_headlines_mobile %>%
  # delete stop words
  anti_join(stop_words) %>%
  # Group by each word
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)

#top 5 Wörter in mobile
unnested_headlines_mobile[1:5,] %>% 
  View()
  
#-----
with_headlines_frontend_fullstack <- with_headlines %>% 
  filter(work_roles == "{Frontend,Fullstack}")

headlines_frontend_fullstack_df <- data_frame(talent_id = with_headlines_frontend_fullstack$talent_id, headline = as.vector(with_headlines_frontend_fullstack$headline))

# split a headline (one row per headline) to one word per row with corresponding talent_id
unnested_headlines_frontend_fullstack <- headlines_frontend_fullstack_df %>%
  unnest_tokens(word, headline)

#
unnested_headlines_frontend_fullstack <- unnested_headlines_frontend_fullstack %>%
  # delete stop words
  anti_join(stop_words) %>%
  # Group by each word
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)

#top 5 Wörter in frontend fullstack
unnested_headlines_frontend_fullstack[1:5,] %>% 
  View()

#---- gesamtübersicht top 5 work roles

top_5_words_per_work_role <- data_frame("{Backend,Fullstack}" = unnested_headlines_backend_fullstack$word[1:5],"{Backend,Fullstack} n" = unnested_headlines_backend_fullstack$n[1:5], "{Backend}" = unnested_headlines_backend$word[1:5], "{Backend} n" = unnested_headlines_backend$n[1:5], "{Frontend}" = unnested_headlines_frontend$word[1:5], "{Frontend} n" = unnested_headlines_frontend$n[1:5],  "{Mobile}" = unnested_headlines_mobile$word[1:5], "{Mobile} n" = unnested_headlines_mobile$n[1:5], "{Frontend,Fullstack}" = unnested_headlines_frontend_fullstack$word[1:5],  "{Frontend,Fullstack} n" = unnested_headlines_frontend_fullstack$n[1:5])

#backend fullstack
unnested_headlines_backend_fullstack[1:5,] %>% 
  ggplot(aes(x = word, y = n)) +
  geom_col() 

#backend 
unnested_headlines_backend[1:5,] %>% 
  ggplot(aes(x = word, y = n)) +
  geom_col() 

#frontend
unnested_headlines_frontend[1:5,] %>% 
  ggplot(aes(x = word, y = n)) +
  geom_col()

#mobile
unnested_headlines_mobile[1:5,] %>% 
  ggplot(aes(x = word, y = n)) +
  geom_col() 

#frontend fullstack
unnested_headlines_frontend_fullstack[1:5,] %>% 
  ggplot(aes(x = word, y = n)) +
  geom_col() 

```

```{r}
install.packages("scales")
install.packages("zoo")

library(scales)
library(zoo)


# welche wörter waren die 5 meist verwendetsten pro monat
batches$created_at <- as.Date(batches$created_at)

batches$month_year <- as.yearmon(batches$created_at)

batches %>% 
  left_join(unnested_headlines) %>% 
  anti_join(stop_words) %>% 
  group_by(month_year) %>% 
  count_("word") %>% 
  View()

View(batches)




B_batches_over_time <- batches %>% 
  group_by(batch_id) %>% 
  count_()

ggplot(B_batches_over_time, aes(x = batch_id, y = n)) + 
  geom_col()

# Erkenntnis!!!!!: was_batched ist inkonsistent, es gibt mehr gebatchete talents in der baches.csv

talent_id_and_count_error_was_batched <- batches %>% 
  left_join(unnested_headlines) %>% 
  left_join(talents) %>%
  filter(was_batched == 0) %>% 
  group_by(talent_id) %>% 
  count_() %>% 
  View()

error_was_batched <- batches %>% 
  left_join(unnested_headlines) %>% 
  left_join(talents) %>%
  filter(was_batched == 0) %>% 
  group_by(talent_id) %>% 
  count_() %>% 
  nrow()

talents

#TODO
#ggplot colchart/barchar bar 1 count was_batched // bar 2 was batched in batches aber was_batched == 0
# eventuell noch talents korrigieren
# um gebatched zu werden brauch man eine headline


data_frame( was_bached = c("talents","batches"), n = c(nrow(with_headlines_was_batched), error_was_batched + nrow(with_headlines_was_batched))) %>% 
  ggplot(aes(x = was_bached, y = n)) +
  geom_col()

batches %>% 
  left_join(unnested_headlines) %>% 
  anti_join(stop_words) %>% 
  group_by(month_year, word) %>% 
  count_() %>% 
  View()
  
talents %>% 
  filter(was_batched == 0, headline != "")

ggplot(batches, aes(x = month_year)) +
  geom_bar()

str(batches)
```


Wordcloud
```{r}
wordcloud(unnested_headlines_total$word[1:200], unnested_headlines_total$n[1:200])

```


headline vs !headline
```{r}
#
with_headlines_was_batched <- with_headlines %>% 
  filter(was_batched == 1)  

# 7 wurden gebatched ohne headline
without_headlines_was_batched <- without_headlines %>% 
  filter(was_batched == 1) 

with_headlines_was_hired <- with_headlines %>% 
  filter(was_hired == 1)

without_headlines_was_hired <- without_headlines %>% 
  filter(was_hired == 1)

# um gebatched zu werden brauch man eine headline
data_frame( headline = c("headline","no headline"), n = c(nrow(with_headlines_was_batched), nrow(without_headlines_was_batched))) %>% 
  ggplot(aes(x = headline, y = n)) +
  geom_col()

# um gehired zu werden muss man gebatched werden (ausnahme von 9)
data_frame( headline = c("headline","no headline"), n = c(nrow(with_headlines_was_hired), nrow(without_headlines_was_hired))) %>% 
  ggplot(aes(x = headline, y = n)) +
  geom_col()

# Ausnahmen: 9 wurden gehired ohne batch
was_hired_without_batched <- talents %>% 
  filter(was_hired == 1, was_batched == 0)


headlines_df_was_hired <- data_frame(talent_id = filter(with_headlines, was_hired == 1)$talent_id, headline = as.vector(filter(with_headlines, was_hired == 1)$headline))

unnested_headlines_was_hired <- headlines_df_was_hired %>%
  unnest_tokens(word, headline) %>% 
  anti_join(stop_words) %>% 
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)

unnested_headlines_total <- headlines_df %>%
  unnest_tokens(word, headline) %>% 
  anti_join(stop_words) %>% 
  group_by(word) %>% 
  count_() %>% 
  arrange(-n)
# Versuch jedem Wort eine Wahrscheinlichkeit zuordnen die zum hired führt
hired_words_propability <- inner_join(unnested_headlines_was_hired, unnested_headlines_total, by = "word")

colnames(hired_words_propability) <- c("word", "n_hired", "n_total")

hired_words_propability <- hired_words_propability %>% 
  mutate(propability = n_hired / n_total )


# ----------------------------------------------------
developer_talents <- unnested_headlines %>% 
  filter(word == "developer") %>% 
  group_by(talent_id) %>% 
  count_() %>% 
  arrange(-n)

developer_talents <- developer_talents %>% 
  inner_join(talents)

summary(developer_talents)

#TODO
# Workexperience headline vs workexperience developer
developer_talents_workexperience <- developer_talents %>% 
  group_by(work_experience) %>% 
  count_()

talents_workexperience <- talents %>% 
  group_by(work_experience) %>% 
  count_()

developer_talents_workexperience <- developer_talents_workexperience %>% 
  filter(work_experience != "") %>% 
  mutate(verhaeltnis = nn/sum(nn))

talents_workexperience <- talents_workexperience %>% 
  filter(work_experience != "", n != 1) %>% 
  mutate(verhaeltnis = n/sum(n))

colnames(developer_talents_workexperience) <- c("work_experience", "n_developer", "verhältnis_developer")

joined_work_experience <- inner_join(developer_talents_workexperience, talents_workexperience)

ggplot(joined_work_experience, aes(x = work_experience, y = verhältnis_developer)) +
geom_col()

# Workexperience hired 
# workexperience total vs workexperience hired 

```


DATA ANALYZATION

Batches

```{r}
#overview of batches
summary(batches)
batches
#ID starts at 9, why? 

# amount of times batched per talent_id hi-lo
batches%>%
  count("talent_id")%>%
arrange(-freq)


```

Salaries

```{r}
# overview of salaries
summary(salaries)

#order by talents hired by city  hi-lo
salaries%>%
    group_by(city) %>%
  summarise(n=n()) %>% 
  arrange(-n)  
#avg min salary per city
salaries%>%
    group_by(city) %>%
summarise(average_sal_min=mean(minimum,na.rm=TRUE)) %>%  
  arrange(-average_sal_min)


#avg max slary per city
salaries%>%
    group_by(city) %>%
summarise(average_sal_max=mean(maximum,na.rm=TRUE)) %>%  
  arrange(-average_sal_max)


```

Talents

```{r}
summary(talents)



talents <- HWR_DATA_talents_subset %>% 
  filter(grepl('AngularJS',headline) & was_hired %in% '1') %>% 
  filter(grepl("\\d",headline) | grepl("\\w",headline))

# Hired Rate ?!?! no_headline <- talents %>% select(grepl("\\d",headline) | !grepl("\\w",headline))




summary(no_headline)

```

```{r}

```

```{r}
 
# MOST USED WORDS IN HEADLINES   (source: https://www.tidytextmining.com/tidytext.html#the-unnest_tokens-function)
# turn headlines into C(Stings)
hltext <- c(toString(talents$headline))

library(dplyr) 
#putting all strings in one line
text_df <- data_frame(line = 1:1, text = hltext)

library(ggplot2)
#create new data "countwords" for text mining
countwords <- text_df%>%
#seperating 1 word per line
unnest_tokens(word,text)%>%
#remove common words like "a". "and" etc.
anti_join(stop_words)%>%
#count each word
count(word, sort = TRUE) 

countwords%>%
#filter words that accure at least twice
filter(n > 2) %>%
mutate(word = reorder(word, n)) %>%
#plot graph
ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
